# Специфікація: Вирішення проблеми Event Loop та Мульти-користувацький доступ

## 1. Коротке РЕЗЮМЕ (Executive Summary)
Ця специфікація описує архітектурне рішення для усунення конфліктів асинхронного циклу (Event Loop) між MCP-клієнтом та сервером, а також перехід на мульти-користувацьку модель доступу до графової бази даних FalkorDB для паралельної роботи декількох суб-агентів.

## 2. Опис Проблеми
Поточна архітектура має дві критичні проблеми:
1. **Клієнтська проблема (Блокування Event Loop):** Спроба вручну ініціалізувати `mcp.client.session.ClientSession` всередині інструменту `run_agent_task` (який вже працює в асинхронному циклі `FastMCP`) призводить до `RuntimeError: This event loop is already running`.
2. **Серверна проблема (Синхронний I/O):** Сервер `falkordb-mcp` використовує синхронну бібліотеку `falkordb`. Якщо один суб-агент робить запит до графа, весь процес FastAPI блокується, унеможливлюючи одночасні запити від інших агентів.

## 3. Критерії Успіху
- **Стабільність клієнта:** Модель всередині `llm_provider_mcp` успішно викликає інструменти FalkorDB без помилок `asyncio`.
- **Мульти-користувацькість (Concurrency):** `falkordb-mcp` сервер здатний обробляти безліч паралельних запитів від різних суб-агентів без блокування (Event Loop starvation).
- **Масштабованість:** Можливість додавати нові MCP-сервери під керування внутрішньої моделі лише шляхом редагування локального JSON-конфігу.

## 4. Шлях Користувача (User Journey Flow) - Життєвий цикл запиту
1. **Оркестрація:** Головний агент викликає `run_agent_task` у `llm_provider_mcp`, передаючи запит (напр., "Проаналізуй граф").
2. **Ініціалізація інструментів:** Внутрішня оболонка агента зчитує `llm_provider_mcp/.gemini/antigravity/mcp_config.json` і "прозоро" для себе підключається до `grynya-mcp-server`.
3. **Паралельне виконання:** Модель (Gemini/OpenAI) вирішує зробити `tool_call` до БД.
4. **Асинхронна обробка:** `grynya-mcp-server` отримує запит і виконує його через `redis.asyncio` без блокування інших вхідних запитів.

## 5. Технічна Архітектура
### А. Сторона Клієнта (`llm-provider-mcp`)
Замість написання кастомного MCP-клієнтського менеджера, використовується нативний підхід конфігурації через файл `mcp_config.json` всередині контейнера. 
Це дозволяє базовому фреймворку (чи офіційним SDK агента) автоматично піднімати `ClientSession` і прив'язувати інструменти до промпту перед викликом LLM.

### Б. Сторона Сервера (`grynya-mcp-server`) - ВАРІАНТ А
Повний рефакторинг `mcp/main.py` для використання драйвера `redis.asyncio` (замість стандартного `falkordb`). 
**Ключові зміни:**
- Заміна `falkordb.FalkorDB` на `redis.asyncio.from_url(...)`.
- Всі функції в `@mcp.tool()` стають на 100% неблокуючими (non-blocking I/O).
- Створення асинхронного механізму парсингу Cypher-відповідей, так як `redis.asyncio` працює з сирими байтовими масивами GraphQL/FalkorDB (необхідно імплементувати графічний мапінг результатів).

## 6. Що "Поза рамками" (Out of Scope)
- В цьому рефакторингу ми **НЕ** змінюємо схему самої бази даних.
- Ми **НЕ** додаємо нових MCP інструментів для графа (лише переписуємо існуючі на асинхронні).
- Ми **НЕ** імплементуємо черги (Celery / Redis Queue), оскільки асинхронного I/O достатньо для поточного навантаження.

## 7. Ризики
- Перехід на `redis.asyncio` вимагає розуміння того, як працює модуль `GRAPH.QUERY` на рівні сирого Redis (Redis Stack), оскільки офіційна бібліотека `falkordb` бере на себе парсинг результатів (нодів, ребер) з масиву Redis у Python-об'єкти. Можливо, доведеться власноруч написати парсер відповідей.

---
*Специфікація затверджена. Наступний крок: Написання Плану Розробки (Project Planner) або безпосередня реалізація рефакторингу `main.py`.*
